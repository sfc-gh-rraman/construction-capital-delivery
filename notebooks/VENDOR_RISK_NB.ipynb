{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè¢ Vendor Risk Scorer\n",
        "\n",
        "## ATLAS Capital Delivery - Subcontractor Performance Model\n",
        "\n",
        "This notebook builds an XGBoost model to score vendor/subcontractor risk:\n",
        "- Analyzes change order history, on-time performance, quality metrics\n",
        "- Compares against trade category benchmarks\n",
        "- Provides composite risk score (0-100)\n",
        "- SHAP explanations for procurement decisions\n",
        "\n",
        "**Business Value**: Identify risky subcontractors before contract award."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from snowflake.snowpark import Session\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import shap\n",
        "\n",
        "# Connect to Snowflake\n",
        "connection_params = {\"connection_name\": \"demo\"}\n",
        "session = Session.builder.configs(connection_params).create()\n",
        "session.use_database(\"CAPITAL_PROJECTS_DB\")\n",
        "session.use_warehouse(\"CAPITAL_ML_WH\")\n",
        "print(f\"Connected: {session.get_current_account()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load vendor data with CO aggregates\n",
        "vendors_df = session.table(\"ATOMIC.VENDOR\").to_pandas()\n",
        "\n",
        "# Get CO statistics per vendor\n",
        "co_stats = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        VENDOR_ID,\n",
        "        COUNT(*) as co_count,\n",
        "        SUM(APPROVED_AMOUNT) as co_total,\n",
        "        AVG(APPROVED_AMOUNT) as co_avg,\n",
        "        COUNT(DISTINCT PROJECT_ID) as project_count,\n",
        "        SUM(CASE WHEN ML_CATEGORY = 'SCOPE_GAP' THEN 1 ELSE 0 END) as scope_gap_count,\n",
        "        SUM(CASE WHEN APPROVAL_LEVEL = 'AUTO' THEN 1 ELSE 0 END) as auto_approved_count\n",
        "    FROM ATOMIC.CHANGE_ORDER\n",
        "    WHERE STATUS = 'APPROVED'\n",
        "    GROUP BY VENDOR_ID\n",
        "\"\"\").to_pandas()\n",
        "\n",
        "# Merge\n",
        "df = vendors_df.merge(co_stats, on='VENDOR_ID', how='left').fillna(0)\n",
        "print(f\"Vendors loaded: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "df['CO_RATE'] = df['co_count'] / (df['project_count'] + 1)  # COs per project\n",
        "df['SCOPE_GAP_RATIO'] = df['scope_gap_count'] / (df['co_count'] + 1)\n",
        "df['AUTO_APPROVE_RATIO'] = df['auto_approved_count'] / (df['co_count'] + 1)\n",
        "\n",
        "feature_cols = ['AVG_CO_RATE', 'ONTIME_DELIVERY_RATE', 'QUALITY_SCORE', \n",
        "                'CO_RATE', 'SCOPE_GAP_RATIO', 'AUTO_APPROVE_RATIO', 'co_total']\n",
        "\n",
        "# Fill missing values\n",
        "for col in feature_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna(df[col].median() if df[col].median() > 0 else 50)\n",
        "\n",
        "# Target: existing risk score (or could train on historical outcomes)\n",
        "X = df[feature_cols].values\n",
        "y = df['RISK_SCORE'].values\n",
        "\n",
        "print(f\"Features: {feature_cols}\")\n",
        "print(f\"Risk score range: {y.min():.0f} - {y.max():.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"R¬≤ Score: {r2_score(y_test, y_pred):.3f}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.1f} points\")\n",
        "\n",
        "# SHAP analysis\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': np.abs(shap_values).mean(0)\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\\\nüìä Top Risk Factors:\")\n",
        "for _, row in importance_df.iterrows():\n",
        "    print(f\"  ‚Ä¢ {row['feature']}: {row['importance']:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate risk scores for all vendors\n",
        "all_scores = model.predict(X).clip(0, 100)\n",
        "\n",
        "# Create output dataframe\n",
        "score_df = df[['VENDOR_ID']].copy()\n",
        "score_df['RISK_SCORE'] = all_scores.astype(int)\n",
        "score_df['RISK_TIER'] = pd.cut(all_scores, bins=[0, 30, 50, 70, 100], \n",
        "                                labels=['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'])\n",
        "score_df['SCORE_DATE'] = pd.Timestamp.now().date()\n",
        "score_df['MODEL_NAME'] = 'VENDOR_RISK_SCORER'\n",
        "score_df['MODEL_VERSION'] = '1.0'\n",
        "\n",
        "# Add component scores\n",
        "score_df['CO_RATE_SCORE'] = (df['CO_RATE'] / df['CO_RATE'].max() * 100).fillna(50).astype(int)\n",
        "score_df['ONTIME_SCORE'] = ((1 - df['ONTIME_DELIVERY_RATE']) * 100).fillna(50).astype(int)\n",
        "score_df['QUALITY_SCORE'] = (100 - df['QUALITY_SCORE']).fillna(50).astype(int)\n",
        "\n",
        "# Save to Snowflake\n",
        "sp_scores = session.create_dataframe(score_df)\n",
        "sp_scores.write.mode('overwrite').save_as_table('ML.VENDOR_RISK_SCORES')\n",
        "\n",
        "print(\"\\\\nüè¢ Vendor Risk Summary:\")\n",
        "print(score_df['RISK_TIER'].value_counts())\n",
        "print(f\"\\\\nHighest risk vendor: {df.loc[all_scores.argmax(), 'VENDOR_NAME']}\")\n",
        "print(\"\\\\n‚úÖ Risk scores saved to ML.VENDOR_RISK_SCORES\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify Apex Electrical - the key vendor in Hidden Discovery\n",
        "apex = df[df['VENDOR_NAME'] == 'Apex Electrical Services']\n",
        "if len(apex) > 0:\n",
        "    apex_row = apex.iloc[0]\n",
        "    print(\"üîç APEX ELECTRICAL ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Risk Score: {apex_row['RISK_SCORE']:.0f}/100\")\n",
        "    print(f\"CO Count: {apex_row['co_count']:.0f}\")\n",
        "    print(f\"Scope Gap COs: {apex_row['scope_gap_count']:.0f}\")\n",
        "    print(f\"Total CO Amount: ${apex_row['co_total']:,.0f}\")\n",
        "    print(f\"On-Time Rate: {apex_row['ONTIME_DELIVERY_RATE']*100:.0f}%\")\n",
        "    print(\"\\\\n‚ö†Ô∏è This vendor is central to the Hidden Discovery pattern!\")\n",
        "\n",
        "session.close()\n",
        "print(\"\\\\n‚úÖ Notebook complete!\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
