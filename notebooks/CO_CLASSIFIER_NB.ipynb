{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç Change Order Classifier\n",
        "\n",
        "## ATLAS Capital Delivery - ML Model for Hidden Discovery\n",
        "\n",
        "This notebook builds the CO Classifier model that enables the \"Hidden Discovery\" feature:\n",
        "- Classifies change orders into categories (SCOPE_GAP, DESIGN_ERROR, FIELD_CONDITION, etc.)\n",
        "- Uses text features from reason_text field\n",
        "- Provides SHAP explanations for transparency\n",
        "- Enables clustering for pattern detection\n",
        "\n",
        "**Key Outcome**: Identify that 156 small COs across 12 projects share a common root cause - missing grounding specifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Snowpark imports\n",
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark.functions import col, lit\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import shap\n",
        "\n",
        "# Create Snowpark session\n",
        "connection_params = {\"connection_name\": \"demo\"}\n",
        "session = Session.builder.configs(connection_params).create()\n",
        "session.use_database(\"CAPITAL_PROJECTS_DB\")\n",
        "session.use_schema(\"ATOMIC\")\n",
        "print(f\"Connected to: {session.get_current_account()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load change orders and extract text features\n",
        "co_df = session.table(\"CHANGE_ORDER\").to_pandas()\n",
        "print(f\"Loaded {len(co_df)} change orders\")\n",
        "\n",
        "def extract_features(text):\n",
        "    text_lower = str(text).lower()\n",
        "    return {\n",
        "        'has_grounding': 1 if 'ground' in text_lower else 0,\n",
        "        'has_missing': 1 if 'missing' in text_lower or 'not included' in text_lower else 0,\n",
        "        'has_omitted': 1 if 'omit' in text_lower else 0,\n",
        "        'has_not_specified': 1 if 'not specified' in text_lower else 0,\n",
        "        'has_unforeseen': 1 if 'unforeseen' in text_lower else 0,\n",
        "        'has_error': 1 if 'error' in text_lower else 0,\n",
        "        'text_length': len(text_lower)\n",
        "    }\n",
        "\n",
        "features = co_df['REASON_TEXT'].apply(extract_features).apply(pd.Series)\n",
        "X = features.values\n",
        "y = co_df['CO_TYPE'].fillna('OTHER').values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost classifier\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "model = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, model.predict(X_test), target_names=le.classes_))\n",
        "\n",
        "# SHAP analysis\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "print(\"\\nTop features by importance:\", features.columns[np.argsort(-np.abs(shap_values[0]).mean(0))[:5]].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate Hidden Discovery - Grounding Pattern\n",
        "grounding_mask = co_df['REASON_TEXT'].str.lower().str.contains('ground', na=False)\n",
        "grounding_cos = co_df[grounding_mask]\n",
        "\n",
        "print(\"üîç HIDDEN DISCOVERY VALIDATION\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Grounding-related COs: {len(grounding_cos)}\")\n",
        "print(f\"Projects Affected: {grounding_cos['PROJECT_ID'].nunique()}\")\n",
        "print(f\"Total Amount: ${grounding_cos['APPROVED_AMOUNT'].sum():,.0f}\")\n",
        "print(f\"Average CO Size: ${grounding_cos['APPROVED_AMOUNT'].mean():,.0f}\")\n",
        "print(f\"\\n‚úÖ Pattern confirmed - systemic design gap identified!\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
