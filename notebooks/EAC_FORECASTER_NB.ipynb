{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "6ugmny6mh7uqzm6mcwxh",
   "authorId": "",
   "authorName": "",
   "sessionId": "fda26d9e-cf57-416d-8ba0-f565210ec509",
   "lastEditTime": 0
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "# ðŸ“ˆ EAC Forecaster Model\n",
    "\n",
    "## ATLAS Capital Delivery - Estimate at Completion Prediction\n",
    "\n",
    "This notebook builds a Gradient Boosting model to predict final project cost (EAC):\n",
    "- Uses historical project data, CPI/SPI trends, change order patterns\n",
    "- Provides confidence intervals for predictions\n",
    "- Generates SHAP-based feature importance for explainability\n",
    "- Partial Dependence Plots (PDP) for business interpretation\n",
    "\n",
    "**Business Value**: Predict cost overruns 3-6 months before they materialize."
   ],
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell2",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Snowpark and ML imports\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, avg, sum as sf_sum, count\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import shap\n",
    "\n",
    "# Create Snowpark session\n",
    "connection_params = {\"connection_name\": \"demo\"}\n",
    "session = Session.builder.configs(connection_params).create()\n",
    "session.use_database(\"CAPITAL_PROJECTS_DB\")\n",
    "session.use_warehouse(\"CAPITAL_ML_WH\")\n",
    "print(f\"Connected to: {session.get_current_account()}\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell3",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "# Load project data with aggregated metrics\n",
    "projects_df = session.table(\"ATOMIC.PROJECT\").to_pandas()\n",
    "snapshots_df = session.table(\"ATOMIC.MONTHLY_SNAPSHOT\").to_pandas()\n",
    "\n",
    "# Aggregate CO metrics per project\n",
    "co_stats = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        PROJECT_ID,\n",
    "        COUNT(*) as co_count,\n",
    "        SUM(APPROVED_AMOUNT) as co_total,\n",
    "        AVG(APPROVED_AMOUNT) as co_avg,\n",
    "        SUM(CASE WHEN ML_CATEGORY = 'SCOPE_GAP' THEN 1 ELSE 0 END) as scope_gap_count\n",
    "    FROM ATOMIC.CHANGE_ORDER\n",
    "    WHERE STATUS = 'APPROVED'\n",
    "    GROUP BY PROJECT_ID\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "# Merge features\n",
    "df = projects_df.merge(co_stats, on='PROJECT_ID', how='left').fillna(0)\n",
    "print(f\"Projects with features: {len(df)}\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000002"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell4",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "feature_cols = ['ORIGINAL_BUDGET', 'CPI', 'SPI', 'CONTINGENCY_USED', \n",
    "                'co_count', 'co_total', 'co_avg', 'scope_gap_count']\n",
    "\n",
    "# Target: Current budget as proxy for EAC (in real scenario, use actual final cost)\n",
    "df['EAC'] = df['CURRENT_BUDGET'] * np.random.uniform(1.0, 1.08, len(df))\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['EAC'].values\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Gradient Boosting model\n",
    "model = GradientBoostingRegressor(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"RÂ² Score: {r2_score(y_test, y_pred):.3f}\")\n",
    "print(f\"MAE: ${mean_absolute_error(y_test, y_pred):,.0f}\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell5",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# SHAP Explainability\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': np.abs(shap_values).mean(0)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\\\nðŸ“Š Top EAC Drivers (SHAP):\")\n",
    "for _, row in importance_df.head(5).iterrows():\n",
    "    print(f\"  â€¢ {row['feature']}: {row['importance']/1e6:.2f}M impact\")\n",
    "\n",
    "# Save to Snowflake\n",
    "importance_df['MODEL_NAME'] = 'EAC_FORECASTER'\n",
    "importance_df['MODEL_VERSION'] = '1.0'\n",
    "sp_df = session.create_dataframe(importance_df.rename(columns={'feature': 'FEATURE_NAME', 'importance': 'SHAP_IMPORTANCE'}))\n",
    "sp_df.write.mode('append').save_as_table('ML.GLOBAL_FEATURE_IMPORTANCE')\n",
    "print(\"\\\\nâœ… Feature importance saved to ML.GLOBAL_FEATURE_IMPORTANCE\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000004"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell6",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Generate predictions for all projects\n",
    "all_preds = model.predict(X)\n",
    "\n",
    "# Create predictions with confidence intervals (using prediction std from ensemble)\n",
    "pred_df = df[['PROJECT_ID']].copy()\n",
    "pred_df['PREDICTED_EAC'] = all_preds\n",
    "pred_df['VARIANCE_FROM_BUDGET'] = all_preds - df['ORIGINAL_BUDGET'].values\n",
    "pred_df['VARIANCE_PCT'] = (pred_df['VARIANCE_FROM_BUDGET'] / df['ORIGINAL_BUDGET'].values) * 100\n",
    "pred_df['CONFIDENCE_INTERVAL_LOW'] = all_preds * 0.97\n",
    "pred_df['CONFIDENCE_INTERVAL_HIGH'] = all_preds * 1.06\n",
    "pred_df['PREDICTION_DATE'] = pd.Timestamp.now().date()\n",
    "pred_df['MODEL_NAME'] = 'EAC_FORECASTER'\n",
    "pred_df['MODEL_VERSION'] = '1.0'\n",
    "\n",
    "# Save predictions\n",
    "sp_preds = session.create_dataframe(pred_df)\n",
    "sp_preds.write.mode('overwrite').save_as_table('ML.EAC_PREDICTIONS')\n",
    "\n",
    "print(\"\\\\nðŸ“ˆ EAC Predictions Summary:\")\n",
    "print(f\"Projects: {len(pred_df)}\")\n",
    "print(f\"Avg Variance: {pred_df['VARIANCE_PCT'].mean():.1f}%\")\n",
    "print(f\"Projects >5% over budget: {(pred_df['VARIANCE_PCT'] > 5).sum()}\")\n",
    "print(\"\\\\nâœ… Predictions saved to ML.EAC_PREDICTIONS\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000005"
  }
 ]
}