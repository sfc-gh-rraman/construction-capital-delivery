{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“… Schedule Slip Predictor\n",
        "\n",
        "## ATLAS Capital Delivery - Activity Delay Risk Model\n",
        "\n",
        "This notebook builds a Random Forest classifier to predict schedule slip probability:\n",
        "- Analyzes activity characteristics, float, dependencies\n",
        "- Incorporates vendor performance history\n",
        "- Provides calibrated probabilities for reliable alerts\n",
        "- SHAP values explain individual predictions\n",
        "\n",
        "**Business Value**: Identify at-risk activities before they impact critical path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from snowflake.snowpark import Session\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score, brier_score_loss\n",
        "import shap\n",
        "\n",
        "# Connect to Snowflake\n",
        "connection_params = {\"connection_name\": \"demo\"}\n",
        "session = Session.builder.configs(connection_params).create()\n",
        "session.use_database(\"CAPITAL_PROJECTS_DB\")\n",
        "session.use_warehouse(\"CAPITAL_ML_WH\")\n",
        "print(f\"Connected: {session.get_current_account()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load activity and vendor data\n",
        "activities_df = session.table(\"ATOMIC.PROJECT_ACTIVITY\").to_pandas()\n",
        "vendors_df = session.table(\"ATOMIC.VENDOR\").to_pandas()\n",
        "\n",
        "# Merge vendor risk scores\n",
        "df = activities_df.merge(\n",
        "    vendors_df[['VENDOR_ID', 'RISK_SCORE', 'ONTIME_DELIVERY_RATE']], \n",
        "    left_on='ASSIGNED_VENDOR_ID', \n",
        "    right_on='VENDOR_ID', \n",
        "    how='left'\n",
        ").fillna({'RISK_SCORE': 50, 'ONTIME_DELIVERY_RATE': 0.85})\n",
        "\n",
        "print(f\"Activities loaded: {len(df)}\")\n",
        "print(f\"Critical path activities: {df['IS_CRITICAL'].sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature engineering\n",
        "df['IS_CRITICAL_NUM'] = df['IS_CRITICAL'].astype(int)\n",
        "df['FLOAT_DAYS'] = df['TOTAL_FLOAT'].fillna(30)\n",
        "df['DURATION'] = df['PLANNED_DURATION'].fillna(30)\n",
        "df['PROGRESS'] = df['PERCENT_COMPLETE'].fillna(0) / 100\n",
        "\n",
        "# Create target: did activity slip? (simulate based on characteristics)\n",
        "np.random.seed(42)\n",
        "slip_prob = (\n",
        "    0.1 + \n",
        "    0.3 * df['IS_CRITICAL_NUM'] + \n",
        "    0.2 * (df['FLOAT_DAYS'] < 5).astype(int) +\n",
        "    0.15 * (df['RISK_SCORE'] / 100) +\n",
        "    np.random.uniform(-0.1, 0.1, len(df))\n",
        ").clip(0, 1)\n",
        "df['SLIPPED'] = (np.random.random(len(df)) < slip_prob).astype(int)\n",
        "\n",
        "print(f\"Slip rate: {df['SLIPPED'].mean()*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features and train model\n",
        "feature_cols = ['IS_CRITICAL_NUM', 'FLOAT_DAYS', 'DURATION', 'PROGRESS', \n",
        "                'RISK_SCORE', 'ONTIME_DELIVERY_RATE']\n",
        "\n",
        "X = df[feature_cols].values\n",
        "y = df['SLIPPED'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest with calibration for reliable probabilities\n",
        "base_model = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
        "model = CalibratedClassifierCV(base_model, method='isotonic', cv=3)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "print(f\"AUC-ROC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
        "print(f\"Brier Score: {brier_score_loss(y_test, y_prob):.4f} (lower is better)\")\n",
        "print(classification_report(y_test, (y_prob > 0.5).astype(int)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions for all activities\n",
        "all_probs = model.predict_proba(X)[:, 1]\n",
        "\n",
        "# Create prediction dataframe\n",
        "pred_df = df[['ACTIVITY_ID', 'PROJECT_ID']].copy()\n",
        "pred_df['SLIP_PROBABILITY'] = all_probs\n",
        "pred_df['PREDICTED_SLIP_DAYS'] = (all_probs * 15).astype(int)  # Rough estimate\n",
        "pred_df['RISK_LEVEL'] = pd.cut(all_probs, bins=[0, 0.3, 0.5, 0.7, 1.0], \n",
        "                                labels=['LOW', 'MEDIUM', 'HIGH', 'CRITICAL'])\n",
        "pred_df['PREDICTION_DATE'] = pd.Timestamp.now().date()\n",
        "pred_df['MODEL_NAME'] = 'SCHEDULE_SLIP_PREDICTOR'\n",
        "pred_df['MODEL_VERSION'] = '1.0'\n",
        "\n",
        "# Save to Snowflake\n",
        "sp_preds = session.create_dataframe(pred_df)\n",
        "sp_preds.write.mode('overwrite').save_as_table('ML.SCHEDULE_RISK_PREDICTIONS')\n",
        "\n",
        "print(\"\\\\nðŸ“… Schedule Risk Summary:\")\n",
        "print(f\"Total activities: {len(pred_df)}\")\n",
        "print(f\"High/Critical risk: {(pred_df['RISK_LEVEL'].isin(['HIGH', 'CRITICAL'])).sum()}\")\n",
        "print(\"\\\\nâœ… Predictions saved to ML.SCHEDULE_RISK_PREDICTIONS\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
